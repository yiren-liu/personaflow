# PersonaFlow Local Development Environment
# Copy this file to backend/.env.block for local development

# ============================================================================
# LLM Configuration - Local Development
# ============================================================================

# OpenAI Configuration (Development)
OPENAI_API_KEY=sk-your-development-openai-key-here
OPENAI_API_BASE=https://api.openai.com/v1
OPENAI_API_TYPE=openai

# For testing with local models or alternative providers:
# OPENAI_API_BASE=http://localhost:8080/v1
# OPENAI_API_TYPE=openai

# ============================================================================
# Literature Search & Academic APIs
# ============================================================================

# Semantic Scholar API (Free tier for development)
S2_API_KEY=your-semantic-scholar-api-key-here

# ============================================================================
# Database Configuration - Local Development
# ============================================================================

# Supabase Local Development Project
SUPABASE_URL=https://your-dev-project.supabase.co
SUPABASE_SERVICE_KEY=your-supabase-dev-service-key
SUPABASE_JWT_SECRET=your-supabase-dev-jwt-secret

# ============================================================================
# Redis Configuration - Local Development
# ============================================================================

# Local Redis (no password for development)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=

# For Docker development:
# REDIS_HOST=redis

# ============================================================================
# Security Configuration - Development
# ============================================================================

# Generated development encryption key
DECRYPT_KEY=your-auto-generated-32-char-key-here

# ============================================================================
# Development-Specific Settings
# ============================================================================

# Reranker disabled for faster development
RERANKER_TYPE=none

# Development logging
DEBUG=true
LOG_LEVEL=debug

# ============================================================================
# Optional: Local Model Testing
# ============================================================================

# Uncomment to test with local LLM servers

# Ollama local server
# OPENAI_API_BASE=http://localhost:11434/v1
# OPENAI_API_KEY=ollama

# Text Generation Inference
# TGI_URL=http://localhost:8080

# Xinference
# XINFERENCE_API_URL=http://localhost:9997/v1
# XINFERENCE_MODEL_ID=qwen1.5-chat

# ============================================================================
# Development Notes
# ============================================================================

# This configuration is optimized for:
# - Fast iteration and development
# - Minimal external dependencies
# - Easy debugging and testing
# - Cost-effective API usage

# For production deployment, use:
# - Stronger encryption keys
# - Production Supabase project
# - Proper secret management
# - Production-grade Redis configuration
